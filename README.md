# MNIST Digit Classification Project

## Overview
This project implements machine learning models to classify handwritten digits from the MNIST dataset using both Feedforward Neural Networks (FFNN) and Convolutional Neural Networks (CNN). It explores different architectures and techniques to achieve high accuracy in digit recognition tasks.

## Project Details
- **Author**: Salil Lokhande
- **Contact**: salillokhande14@gmail.com

## Contents
- `MNIST Digit Classification Project.ipynb`: Jupyter Notebook showcasing FFNN and CNN implementations.
- `README.md`: This file, providing an overview of the project.

## Dataset
The MNIST dataset is widely used in the machine learning community for benchmarking models. It consists of 60,000 training images and 10,000 test images of handwritten digits (0-9).

You can download the dataset [here](https://drive.google.com/file/d/1YDgR-i0eSo_LGwTiwxbriLH_90MYyKNB/view?usp=sharing).

## Techniques and Libraries Used
### Libraries:
- **TensorFlow**: Deep learning framework for model implementation.
- **Keras**: High-level neural networks API for building and training models.
- **NumPy**: Fundamental package for numerical computing in Python.
- **Matplotlib**: Comprehensive library for creating static, animated, and interactive visualizations in Python.
- **Scikit-learn**: Simple and efficient tools for data mining and data analysis.

### Techniques:
- **Data Augmentation**: Applied techniques such as rotation, scaling, and shifting to increase the diversity of the training set and improve model generalization.
- **Hyperparameter Tuning**: Optimized learning rates, batch sizes, and model architectures to enhance model performance.
- **Model Evaluation**: Utilized metrics including accuracy, precision, recall, and confusion matrices to evaluate and compare FFNN and CNN models.

## Results
- **FFNN Model**: Achieved an accuracy of approximately 96.96% on the test set.
- **CNN Model**: Achieved an accuracy of approximately 98.90% on the test set, demonstrating superior performance over the FFNN model.

## Future Enhancements
- Explore advanced CNN architectures like ResNet or DenseNet.
- Implement ensemble learning techniques for further accuracy improvements.

## Feedback
Your feedback and contributions are welcome! Feel free to reach out to the author for any questions or suggestions.


